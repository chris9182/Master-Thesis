\iffalse \bibliography{../references.bib} \fi

\chapter{Introduction}
\label{cha:Introduction}

The generation of clusterings is quite a difficult task when little knowledge on the data is available. There exist a large number of clustering algorithms that all aim to find a fitting partitioning of the data, but they all come with different assumptions on the data. Taking k-Means as an example, the data is assumed to be Gaussian distributed which might not actually be the case for many data-sets, making it unsuitable for clustering such data. As Chen and Liu \cite{VISTA} also describe in their paper, the process of clustering is not done when a solution is computed, but when the researcher involved ``... evaluated, understood and accepted the patterns.''

To find a suitable methods and results, visual frameworks have been proposed that aim to help finding a fitting clustering by evaluating the results of different algorithms and parameter settings via quality metrics and ranking the clustering solutions. One of these frameworks is Clustervision \cite{Kwon2018ClustervisionVS} whereby different algorithms are run, their solutions are visualized and then ranked according to the average of five different quality metrics.With this, the user is able to look at the ranked candidates through different visualizations and choose a solution as final result. A problem with this approach is though, that any individual metric is biased towards a specific resulting cluster structure, possibly ranking a clustering higher than another one even if it does not fit the data properly. Even the authors of Clustervision themselves mention that ``the effectiveness of these metrics in gauging the quality of the clustering is also difficult to determine due to the lack of ground truth''. Also, as many solutions were calculated and only one of them is chosen in the final decision, a lot of calculated knowledge is ignored.

To overcome this problem, I propose to not use quality metrics for the choice of the best clustering, but to rely on robustness indicators for this selection. Here, robustness can be seen as how resilient a clustering solution is towards introducing additional noise points or small changes in the parameters of the clustering algorithm. As robustness is difficult to evaluate by itself, many different algorithms with different parameters should be used, analyzing where multiple methods or parameter sets find a similar result. Clusterings that are similar to many other results can be seen as robust and finding a consensus of those can result in an even better overall clustering then just choosing one of the calculated results. To find such similar clusterings or groups of similar clusterings meta-clustering can be used. To then compute final candidates, each group of similar results can be merged to a consensus result, capturing the essence of the group. 

Based on this idea I created a tool which will be further described in Chapter \ref{cha:Tool}. Additionally, the tool aims to include the expert user into the process of finding the result. Most research on consensus clustering, as also seen in the survey of Vega-Pons and Ruiz-Shulcloper \cite{survey1}, only briefly mentions how generating or pre-selecting base clusterings can impact the result of consensus clustering, even though this may change the quality of the final solution. For this reason, the tool allows the user to visually explore the clusterings created by the simple clustering algorithms, facilitating the choice of which ones use for the process of merging when trying to obtain a final result for a given data-set.

The rest of this thesis is organized as follows: Firstly, the related work regarding the methods used and existing tools is mentioned (Chapter \ref{cha:related_work}). Next, the theory of the methods used is discussed (Chapter \ref{cha:methods}) and a description of how the tool can be used is given (Chapter \ref{cha:Tool}). After this, additional details on the implementation, used frameworks and extendability of the tool is described (Chapter \ref{cha:impl}). Then, the performed experiments are shown (Chapter \ref{cha:experiments}), ilustrating how the tool is able to outperform simple methods. Lastly, future work and possible research topics based on this thesis' findings are proposed (Chapter \ref{cha:futurework}) and finally this thesis is concluded with the lessons learned and a summarizing reflection (Chapter \ref{cha:conclusion}).
