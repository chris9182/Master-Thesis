\iffalse \bibliography{../references.bib} \fi

\chapter{Introduction}
\label{cha:Introduction}

The generation of clusterings is quite a difficult task when little knowledge on the data is available. There exist a large number of clustering algorithms that all aim to find a fitting partitioning of the data, but they all come with different assumptions on the data. Taking k-Means as an example, the data is assumed to be Gaussian distributed which might not actually be the case for many data-sets, making it unsuitable for clustering such data. As Chen and Liu \cite{VISTA} also describe in their paper, the process of clustering is not done when a solution is computed, but when the researcher involved ``... evaluated, understood and accepted the patterns.''

To find a suitable methods and result, visual frameworks have been proposed that aim to help finding a fitting clustering by evaluating the results of different algorithms and parameter settings via quality metrics and ranking the clustering solutions. One of these frameworks is Clustervision \cite{Kwon2018ClustervisionVS} whereby different algorithms are run, their solutions are visualized and ranked according to the average of five different quality metrics. The user is then able to look at the candidates through different visualizations and choose a solution as final result. A problem with this approach is though, that each metric is biased towards a specific resulting cluster structure, possibly ranking it higher than others even if it does not fit the data properly. Even the authors of Clustervision themselves mention that ``the effectiveness of these metrics in gauging the quality of the clustering is also difficult to determine due to the lack of ground truth''. Also, as many solutions were calculated and only one of them is chosen in the final decision, a lot of calculated knowledge is ignored.

To overcome this problem, I propose to not use quality metrics for the choice of the best clustering, but to rely on robustness indicators for this selection. As robustness is difficult to evaluate by itself many different algorithms with different parameters should be used, analyzing where multiple methods or parameter sets find a similar result. Clusterings that are similar to many other results can be seen as robust and finding a consensus of those can result in an even better overall clustering then just choosing one of the calculated results. To find such similar clusterings or groups of similar clusterings meta-clustering can be used. To then compute final candidates, each group of similar results can be merged to a consensus result, capturing the essence of the group. 

Based on this idea I created a tool which will be further described in Chapter \ref{cha:Tool}. Additionally, the tool aims to include the expert user into the process of finding the result. Most research on consensus clustering, as also seen in the survey of Vega-Pons and Ruiz-Shulcloper \cite{survey1}, only briefly mention how generating or pre-selecting base clusterings can impact the result of consensus clustering, even though this impacts the quality of the final solution. For this reason, the tool allows the user to visually explore the clusterings created by the simple clustering algorithms, facilitating the choice of which ones use for the process of merging when trying to obtain a final result for a given data-set.

The rest of this thesis is organized as follows: [TEXT]

% TODO: describe implementation section and evaluation section textually
