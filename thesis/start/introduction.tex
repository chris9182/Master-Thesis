\iffalse \bibliography{../references.bib} \fi

\chapter{Introduction}
\label{cha:Introduction}

The generation of clusterings is quite a difficult task when little knowledge on the data is available. There exist a large number of clustering algorithms that all aim to find a fitting partitioning of the data, but they all come with different assumptions on the data. Taking k-Means as an example, the data is assumed to be Gaussian distributed which might not actually be the case for many data-sets, making it unsuitable for clustering such data. As Chen and Liu \cite{VISTA} also describe in their paper, the process of clustering is not done when a solution is computed, but when the researcher involved ``... evaluated, understood and accepted the patterns.''

To find suitable methods and results, visual frameworks have been proposed that aim to help in recognizing a fitting clustering by evaluating the results of different algorithms and parameter settings via quality metrics and ranking the clustering solutions. Clustervision \cite{Kwon2018ClustervisionVS} is one of those frameworks whereby different algorithms can be run and their solutions are visualized and ranked according to the average of five different quality metrics. Thus, the user can look at the ranked candidates through different visualizations and choose a solution as the final result. A problem with this approach is though that any individual metric is biased towards a specific resulting cluster structure, possibly ranking a clustering higher than another one, even if it does not fit the data properly. The authors of Clustervision themselves mention that ``the effectiveness of these metrics in gauging the quality of the clustering is also difficult to determine due to the lack of ground truth'' \cite{Kwon2018ClustervisionVS}. Also, as many solutions were calculated and only one of them is used for the final decision, a lot of calculated knowledge is ignored.

To overcome this problem, we propose to not use quality metrics for the choice of the best clustering but to rely on robustness indicators for the selection of the best result. Using this approach, robustness can be seen as how resilient a clustering solution is towards introducing additional noise points or small changes in the parameters of the clustering algorithm. As robustness is difficult to evaluate by itself, many different algorithms with different parameters should be used, to analyze where multiple methods or parameter sets find a similar result. Clusterings that are similar to many other results can be seen as robust and finding a consensus for those can result in an even better overall clustering than just choosing one of the calculated results. To find such similar clusterings or groups of similar clusterings, meta-clustering can be used. For computing the final candidates, each group of similar results can be merged into a consensus result, capturing the essence of the group. 

Based on this idea we created a tool that will be further described in Chapter \ref{cha:Tool}. Additionally, the tool aims to include domain experts in the process of finding the result. Most research on consensus clustering, as also seen in the survey of Vega-Pons and Ruiz-Shulcloper \cite{survey1}, only briefly mentions how generating or pre-selecting base clusterings can impact the result of consensus clustering, even though this may change the quality of the final solution. For this reason, the tool allows the user to visually explore the clusterings created by the simple clustering algorithms, facilitating the choice of which ones use for the process of merging when trying to obtain a final result for a given data-set.

The remaining chapters of this thesis is organized as follows: Firstly, the related work regarding the methods used and existing tools is mentioned (Chapter \ref{cha:related_work}). Next, the theory of the methods used is discussed (Chapter \ref{cha:methods}) and a description of the idea of the tool (Chapter \ref{cha:idea}) and how it can be used (Chapter \ref{cha:Tool}) is given. After this, additional details on the implementation, used frameworks and extendability of the tool are described (Chapter \ref{cha:impl}). Then, the performed experiments are shown (Chapter \ref{cha:experiments}), illustrating how the tool is able to outperform simple methods, with a user being tasked to work on clustering tasks with this tool. Lastly, future work and possible research topics based on the findings are proposed (Chapter \ref{cha:futurework}) and finally, this thesis is concluded with the lessons learned and a summarizing reflection (Chapter \ref{cha:conclusion}).
